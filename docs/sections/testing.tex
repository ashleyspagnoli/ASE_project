\section{Testing}

The project implements a testing strategy covering unit tests, integration tests, and performance tests to ensure system reliability, correctness, and scalability across all microservices.

\subsection{Unit Testing}
All tests are located in \texttt{/docs/tests} as requested.

Unit tests are executed using dedicated Dockerfile\_test files like we've seen in the lectures.\\
We made the following decisions for mocking.
\begin{itemize}
    \item For all microservices the databases are mocked using the mongomock library, installed in the Dockerfile\_test file.
    \item To mock the RabbitMQ for Game History we disabled the loop pinging the RabbitMQ microservice.
    This meant that we needed custom endpoints to add matches and users to the DB in the testing environment.
    \texttt{/addmatches} and \texttt{/addusernames}.
    \item In Game History we also needed to mock the function to get the usernames by ids of User Manager.
\end{itemize}

\textbf{Unit tests execution:}
\begin{itemize}
    \item \textbf{Collection}:\\
    \begin{lstlisting}[language=bash]
docker build -f collection/Dockerfile_test -t collection-test .
docker run -p 5000:5000 collection-test
newman run docs/tests/collection_ut.postman_collection.json --insecure
    \end{lstlisting}
    \item \textbf{Game History}:\\
    \begin{lstlisting}[language=bash]
docker build -f game_history/Dockerfile_test -t history-test .
docker run -p 5000:5000 history-test
newman run docs/tests/game_history_ut.postman_collection.json --insecure
    \end{lstlisting}
    \item \textbf{User Manager}:\\
    \begin{lstlisting}[language=bash]
docker build -f user-manager/Dockerfile_test -t user-manager-test .
docker run -p 5004:5000 user-manager-test
newman run docs/tests/user_manager_ut.postman_collection.json --insecure
    \end{lstlisting}
\end{itemize}

\subsection{Integration Testing}

\begin{itemize}
    \item \textbf{IT-001: Complete Game Workflow - Happy Path}: Tests end-to-end user journey from registration to game completion.
    \item \textbf{IT-002: Authentication \& Authorization}: Verifies login, token validation, and access control enforcement.
    \item \textbf{IT-003: Deck Validation}: Ensures deck building rules and constraints are correctly enforced.
    \item \textbf{IT-004: Game History \& Leaderboard}: Checks match history retrieval and leaderboard accuracy.
    \item \textbf{IT-005: Cross-Service Data Consistency}: Confirms data isolation and consistency across microservices.
    \item \textbf{IT-007: Error Handling \& Edge Cases}: Validates error responses and handling of invalid or edge-case inputs.
\end{itemize}

\textbf{Integration tests execution:}
\begin{itemize}
    \item \textbf{Docker Compose}:\\
    \begin{lstlisting}[language=bash]
# Ensure all services are running
cd src
docker compose up --build

# Run integration tests (from project root)
newman run docs/tests/integration.postman_collection.json --insecure
    \end{lstlisting}
\end{itemize}

Those tests can also 

\begin{center}
    {\Huge\color{red}\textbf{!}}
\end{center}
\textbf{Using Python Script:}
A complete game simulation can be executed programmatically:
\begin{lstlisting}[language=bash]
cd src
python test_match.py
\end{lstlisting}

This script performs:
\begin{enumerate}
    \item Registers two random users with unique credentials
    \item Creates valid decks for both players
    \item Initiates matchmaking and pairs the users
    \item Simulates a complete game with card plays
    \item Displays comprehensive game statistics including:
    \begin{itemize}
        \item Round-by-round results
        \item Final scores
        \item Winner determination
        \item Game duration
    \end{itemize}
\end{enumerate}

\subsection{Performance Testing with Locust}

Performance tests simulate realistic user load to measure system behavior under concurrent access and identify bottlenecks. 
The tests use Locust, a Python-based load testing framework.

\subsubsection{Test Scenarios}

The performance test suite simulates a complete user workflow representing realistic usage patterns:

\begin{enumerate}
    \item \textbf{User Registration}: Creates new accounts with random credentials
    \item \textbf{Authentication}: Performs login and JWT token generation
    \item \textbf{Deck Creation}: Builds valid 8-card decks following game rules
    \item \textbf{Matchmaking}: Joins queue and waits for opponent matching
    \item \textbf{Gameplay}: Simulates complete game sessions with:
    \begin{itemize}
        \item Deck selection for matched game
        \item Iterative card plays
        \item Hand retrieval between turns
        \item Game state validation
    \end{itemize}
    \item \textbf{History Access}: Queries match history and leaderboard data
\end{enumerate}

\subsubsection{User Types}

Three user types with different think times simulate varied usage patterns:

\begin{itemize}
    \item \textbf{QuickUser}: 1-3 second wait time between actions (rapid gameplay)
    \item \textbf{NormalUser}: 3-7 second wait time (typical gameplay)
    \item \textbf{SlowUser}: 5-15 second wait time (casual gameplay)
\end{itemize}

\subsubsection{Implementation Details}

The Locust test implementation (\texttt{docs/locustfile.py}) features:

\begin{itemize}
    \item \textbf{Sequential Task Execution}: \texttt{GameUserFlow} class orchestrates the complete workflow
    \item \textbf{Session Management}: Each user maintains state across requests:
    \begin{itemize}
        \item Username with random suffix (e.g., \texttt{loadtest\_user\_12345})
        \item JWT token for authenticated requests
        \item Active game ID during matches
        \item Selected deck slot
    \end{itemize}
    \item \textbf{SSL Configuration}: Disables certificate verification for self-signed certificates
    \item \textbf{Error Handling}: Graceful handling of concurrent access scenarios:
    \begin{itemize}
        \item 400 responses during registration marked as success, duplicate usernames expected and should not impact on the test results
        \item 401 responses during opponent's turn marked as success, they indicate it's not the user's turn and should not impact on the test results
        \item Failed operations are logged but don't interrupt test flow
    \end{itemize}
\end{itemize}

\subsubsection{Test Execution}

\textbf{Setup:}
\begin{lstlisting}[language=bash]
# Install Locust
pip install locust

# Ensure all services are running
cd src
docker compose up -d
\end{lstlisting}

\textbf{Running Tests:}
\begin{lstlisting}[language=bash]
# Start Locust web interface
cd docs
locust

# Access web UI at http://localhost:8089
\end{lstlisting}

\textbf{Configuration:}
\begin{enumerate}
    \item Set number of users (e.g., 50 concurrent users)
    \item Set spawn rate (e.g., 4 users/second)
    \item Set host: \texttt{https://localhost:8443}
    \item Click "Start" to begin test
\end{enumerate}

\subsubsection{Metrics and Analysis}

Locust provides real-time metrics during test execution:

\begin{itemize}
    \item \textbf{Request Statistics}:
    \begin{itemize}
        \item Requests per second (RPS) by endpoint
        \item Response time percentiles (50th, 95th, 99th)
        \item Failure rates and error types
        \item Average response sizes
    \end{itemize}
    
    \item \textbf{Endpoints}:
    \begin{itemize}
        \item \texttt{/users/register}: user creation
        \item \texttt{/users/login}: authentication
        \item \texttt{/collection/decks}: deck management operations
        \item \texttt{/game/match/join}: matchmaking queue
        \item \texttt{/game/hand}: cards in hand
        \item \texttt{/game/play}: card play action
        \item \texttt{/history/matches}: user's matches history
        \item \texttt{/history/leaderboard}: leaderboard
    \end{itemize}

    % Analisi da terminare
\end{itemize}